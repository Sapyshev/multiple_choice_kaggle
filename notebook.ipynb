{"cells":[{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-09-18T15:35:13.885896Z","iopub.status.busy":"2023-09-18T15:35:13.884877Z","iopub.status.idle":"2023-09-18T15:35:13.890799Z","shell.execute_reply":"2023-09-18T15:35:13.889893Z","shell.execute_reply.started":"2023-09-18T15:35:13.885858Z"},"trusted":true},"outputs":[],"source":["from typing import Optional, Union\n","import pandas as pd, numpy as np, torch\n","from datasets import Dataset\n","from dataclasses import dataclass\n","from transformers import AutoTokenizer\n","from transformers import EarlyStoppingCallback\n","from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n","from transformers import AutoModelForMultipleChoice, TrainingArguments, Trainer, TFAutoModelForMultipleChoice\n","import torch\n","\n","VER=2\n","# TRAIN WITH SUBSET OF 60K\n","NUM_TRAIN_SAMPLES = 60000\n","# PARAMETER EFFICIENT FINE TUNING\n","# PEFT REQUIRES 1XP100 GPU NOT 2XT4\n","USE_PEFT = False\n","# NUMBER OF LAYERS TO FREEZE \n","# DEBERTA LARGE HAS TOTAL OF 24 LAYERS\n","FREEZE_LAYERS = 22\n","# BOOLEAN TO FREEZE EMBEDDINGS\n","FREEZE_EMBEDDINGS = True\n","# LENGTH OF CONTEXT PLUS QUESTION ANSWER\n","MAX_INPUT = 256\n","\n","model_dir = 'microsoft/deberta-v3-large'"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}],"source":["tokenizer = AutoTokenizer.from_pretrained('microsoft/deberta-v3-large')"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[],"source":["df_valid = pd.read_csv('data/train.csv')"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Train data size: (60000, 8)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>prompt</th>\n","      <th>context</th>\n","      <th>A</th>\n","      <th>B</th>\n","      <th>C</th>\n","      <th>D</th>\n","      <th>E</th>\n","      <th>answer</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>55314</th>\n","      <td>What type of molecules are secreted by the cel...</td>\n","      <td>B)) Local hormones are a large group of signal...</td>\n","      <td>messenger molecules</td>\n","      <td>negaitive molecules</td>\n","      <td>-</td>\n","      <td>word molecules</td>\n","      <td>sleeping molecules</td>\n","      <td>A</td>\n","    </tr>\n","    <tr>\n","      <th>4883</th>\n","      <td>What type of sound did Ambrosia adopt on their...</td>\n","      <td>Life Beyond L.A. is the third album by Ambrosi...</td>\n","      <td>The album featured a heavier emphasis on progr...</td>\n","      <td>The album explored a more experimental and ava...</td>\n","      <td>The album experimented with electronic music, ...</td>\n","      <td>The album featured a fusion of progressive roc...</td>\n","      <td>The album marked a departure from their progre...</td>\n","      <td>E</td>\n","    </tr>\n","    <tr>\n","      <th>29115</th>\n","      <td>What is the traditional dish made with pounded...</td>\n","      <td>* Puto kutsinta (typically just called kutsint...</td>\n","      <td>Kiritanpo</td>\n","      <td>Sushi</td>\n","      <td>Gyūtan</td>\n","      <td>Okonomiyaki</td>\n","      <td>Takoyaki</td>\n","      <td>A</td>\n","    </tr>\n","    <tr>\n","      <th>4894</th>\n","      <td>When was Gradius III first released for the Su...</td>\n","      <td>Gradius III is a 1989 scrolling shooter video ...</td>\n","      <td>It was never released for the SNES.</td>\n","      <td>1990</td>\n","      <td>1992</td>\n","      <td>1991</td>\n","      <td>1989</td>\n","      <td>D</td>\n","    </tr>\n","    <tr>\n","      <th>30959</th>\n","      <td>How did the name \"Bhārät\" evolve to refer to t...</td>\n","      <td>Bharat (occasionally also romanised as Bharath...</td>\n","      <td>It was derived from the name of Rishabha's son...</td>\n","      <td>It was derived from the name of Dushyanta's so...</td>\n","      <td>It was officially designated as the name for I...</td>\n","      <td>It was developed as a result of the linguistic...</td>\n","      <td>It was initially used to refer to the western ...</td>\n","      <td>E</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                  prompt  \\\n","55314  What type of molecules are secreted by the cel...   \n","4883   What type of sound did Ambrosia adopt on their...   \n","29115  What is the traditional dish made with pounded...   \n","4894   When was Gradius III first released for the Su...   \n","30959  How did the name \"Bhārät\" evolve to refer to t...   \n","\n","                                                 context  \\\n","55314  B)) Local hormones are a large group of signal...   \n","4883   Life Beyond L.A. is the third album by Ambrosi...   \n","29115  * Puto kutsinta (typically just called kutsint...   \n","4894   Gradius III is a 1989 scrolling shooter video ...   \n","30959  Bharat (occasionally also romanised as Bharath...   \n","\n","                                                       A  \\\n","55314                                messenger molecules   \n","4883   The album featured a heavier emphasis on progr...   \n","29115                                          Kiritanpo   \n","4894                 It was never released for the SNES.   \n","30959  It was derived from the name of Rishabha's son...   \n","\n","                                                       B  \\\n","55314                                negaitive molecules   \n","4883   The album explored a more experimental and ava...   \n","29115                                              Sushi   \n","4894                                                1990   \n","30959  It was derived from the name of Dushyanta's so...   \n","\n","                                                       C  \\\n","55314                                                  -   \n","4883   The album experimented with electronic music, ...   \n","29115                                             Gyūtan   \n","4894                                                1992   \n","30959  It was officially designated as the name for I...   \n","\n","                                                       D  \\\n","55314                                     word molecules   \n","4883   The album featured a fusion of progressive roc...   \n","29115                                        Okonomiyaki   \n","4894                                                1991   \n","30959  It was developed as a result of the linguistic...   \n","\n","                                                       E answer  \n","55314                                 sleeping molecules      A  \n","4883   The album marked a departure from their progre...      E  \n","29115                                           Takoyaki      A  \n","4894                                                1989      D  \n","30959  It was initially used to refer to the western ...      E  "]},"execution_count":39,"metadata":{},"output_type":"execute_result"}],"source":["df_train = pd.read_csv('data/all_12_with_context2.csv')\n","df_train = df_train.drop(columns=\"source\")\n","df_train = df_train.fillna('-').sample(NUM_TRAIN_SAMPLES)\n","print('Train data size:', df_train.shape )\n","df_train.head()"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[{"data":{"text/plain":["answer\n","A    12735\n","C    12347\n","B    12239\n","D    11876\n","E    10803\n","Name: count, dtype: int64"]},"execution_count":40,"metadata":{},"output_type":"execute_result"}],"source":["df_train.answer.value_counts()"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[{"data":{"text/plain":["answer\n","B    10000\n","A    10000\n","C    10000\n","E    10000\n","D    10000\n","Name: count, dtype: int64"]},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":["# Sample 10,000 samples for each label\n","sampled_data = []\n","\n","for label in ['A', 'C', 'B', 'D', 'E']:\n","    label_data = df_train[df_train['answer'] == label]\n","    sampled_data.append(label_data.sample(n=10000, replace=True))\n","\n","# Create a new DataFrame with the sampled data\n","balanced_df = pd.concat(sampled_data)\n","\n","# Shuffle the rows to randomize the order\n","balanced_df = balanced_df.sample(frac=1).reset_index(drop=True)\n","balanced_df.answer.value_counts()"]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","train_data, validation_set = train_test_split(balanced_df, test_size=1000, stratify=balanced_df['answer'], random_state=42)"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[{"data":{"text/plain":["(1189, 9)"]},"execution_count":43,"metadata":{},"output_type":"execute_result"}],"source":["valid = pd.concat([df_valid, validation_set], axis=0)\n","\n","# If you want to reset the index of the concatenated DataFrame\n","valid.reset_index(drop=True, inplace=True)\n","valid.drop_duplicates(subset='prompt', inplace=True)\n","valid.shape"]},{"cell_type":"code","execution_count":44,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/var/folders/53/zdvtpqvs6qxf5ht0lhmgw37c0000gp/T/ipykernel_10326/3311486597.py:2: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  filtered_train_data.drop_duplicates(subset='prompt', inplace=True)\n"]},{"data":{"text/plain":["(30973, 8)"]},"execution_count":44,"metadata":{},"output_type":"execute_result"}],"source":["filtered_train_data = train_data[~train_data['prompt'].isin(valid['prompt'])]\n","filtered_train_data.drop_duplicates(subset='prompt', inplace=True)\n","filtered_train_data.shape"]},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[],"source":["options = 'ABCDE'"]},{"cell_type":"code","execution_count":46,"metadata":{},"outputs":[],"source":["option_to_index = {option: idx for idx, option in enumerate('ABCDE')}\n","index_to_option = {v: k for k,v in option_to_index.items()}\n","\n","def preprocess(example):\n","    first_sentence = [ \"[CLS] \" + example['context'] ] * 5\n","    second_sentences = [\" #### \" + example['prompt'] + \" [SEP] \" + example[option] + \" [SEP]\" for option in 'ABCDE']\n","    tokenized_example = tokenizer(first_sentence, second_sentences, truncation='only_first', \n","                                  max_length=MAX_INPUT, add_special_tokens=False)\n","    tokenized_example['label'] = option_to_index[example['answer']]\n","    \n","    return tokenized_example\n","\n","@dataclass\n","class DataCollatorForMultipleChoice:\n","    tokenizer: PreTrainedTokenizerBase\n","    padding: Union[bool, str, PaddingStrategy] = True\n","    max_length: Optional[int] = None\n","    pad_to_multiple_of: Optional[int] = None\n","    \n","    def __call__(self, features):\n","        label_name = 'label' if 'label' in features[0].keys() else 'labels'\n","        labels = [feature.pop(label_name) for feature in features]\n","        batch_size = len(features)\n","        num_choices = len(features[0]['input_ids'])\n","        flattened_features = [\n","            [{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features\n","        ]\n","        flattened_features = sum(flattened_features, [])\n","        \n","        batch = self.tokenizer.pad(\n","            flattened_features,\n","            padding=self.padding,\n","            max_length=self.max_length,\n","            pad_to_multiple_of=self.pad_to_multiple_of,\n","            return_tensors='pt',\n","        )\n","        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n","        batch['labels'] = torch.tensor(labels, dtype=torch.int64)\n","        return batch"]},{"cell_type":"code","execution_count":47,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","/Users/rollansapyshev/miniconda3/envs/zoomcamp/lib/python3.11/site-packages/transformers/convert_slow_tokenizer.py:473: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n","  warnings.warn(\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"data":{"text/plain":["Dataset({\n","    features: ['prompt', 'context', 'A', 'B', 'C', 'D', 'E', 'answer'],\n","    num_rows: 30973\n","})"]},"execution_count":47,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer = AutoTokenizer.from_pretrained(model_dir)\n","dataset_valid = Dataset.from_pandas(valid)\n","dataset = Dataset.from_pandas(filtered_train_data)\n","dataset = dataset.remove_columns([\"__index_level_0__\"])\n","dataset"]},{"cell_type":"code","execution_count":48,"metadata":{},"outputs":[{"data":{"text/plain":["Dataset({\n","    features: ['id', 'prompt', 'A', 'B', 'C', 'D', 'E', 'answer', 'context', '__index_level_0__'],\n","    num_rows: 1189\n","})"]},"execution_count":48,"metadata":{},"output_type":"execute_result"}],"source":["dataset_valid"]},{"cell_type":"code","execution_count":49,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["\n","Map:   0%|          | 0/1189 [00:00<?, ? examples/s]\n"]},{"ename":"TypeError","evalue":"can only concatenate str (not \"NoneType\") to str","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[49], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tokenized_dataset_valid \u001b[39m=\u001b[39m dataset_valid\u001b[39m.\u001b[39;49mmap(preprocess, remove_columns\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mprompt\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mcontext\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mA\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mB\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mD\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mE\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39manswer\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m      2\u001b[0m tokenized_dataset \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39mmap(preprocess, remove_columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mprompt\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcontext\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mA\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mB\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mC\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mD\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mE\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39manswer\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m      3\u001b[0m tokenized_dataset\n","File \u001b[0;32m~/miniconda3/envs/zoomcamp/lib/python3.11/site-packages/datasets/arrow_dataset.py:592\u001b[0m, in \u001b[0;36mtransmit_tasks.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    590\u001b[0m     \u001b[39mself\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mself\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    591\u001b[0m \u001b[39m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 592\u001b[0m out: Union[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mDatasetDict\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    593\u001b[0m datasets: List[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(out\u001b[39m.\u001b[39mvalues()) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(out, \u001b[39mdict\u001b[39m) \u001b[39melse\u001b[39;00m [out]\n\u001b[1;32m    594\u001b[0m \u001b[39mfor\u001b[39;00m dataset \u001b[39min\u001b[39;00m datasets:\n\u001b[1;32m    595\u001b[0m     \u001b[39m# Remove task templates if a column mapping of the template is no longer valid\u001b[39;00m\n","File \u001b[0;32m~/miniconda3/envs/zoomcamp/lib/python3.11/site-packages/datasets/arrow_dataset.py:557\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    550\u001b[0m self_format \u001b[39m=\u001b[39m {\n\u001b[1;32m    551\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_type,\n\u001b[1;32m    552\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mformat_kwargs\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_kwargs,\n\u001b[1;32m    553\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_columns,\n\u001b[1;32m    554\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39moutput_all_columns\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_all_columns,\n\u001b[1;32m    555\u001b[0m }\n\u001b[1;32m    556\u001b[0m \u001b[39m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 557\u001b[0m out: Union[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mDatasetDict\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    558\u001b[0m datasets: List[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(out\u001b[39m.\u001b[39mvalues()) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(out, \u001b[39mdict\u001b[39m) \u001b[39melse\u001b[39;00m [out]\n\u001b[1;32m    559\u001b[0m \u001b[39m# re-apply format to the output\u001b[39;00m\n","File \u001b[0;32m~/miniconda3/envs/zoomcamp/lib/python3.11/site-packages/datasets/arrow_dataset.py:3097\u001b[0m, in \u001b[0;36mDataset.map\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   3090\u001b[0m \u001b[39mif\u001b[39;00m transformed_dataset \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   3091\u001b[0m     \u001b[39mwith\u001b[39;00m logging\u001b[39m.\u001b[39mtqdm(\n\u001b[1;32m   3092\u001b[0m         disable\u001b[39m=\u001b[39m\u001b[39mnot\u001b[39;00m logging\u001b[39m.\u001b[39mis_progress_bar_enabled(),\n\u001b[1;32m   3093\u001b[0m         unit\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m examples\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   3094\u001b[0m         total\u001b[39m=\u001b[39mpbar_total,\n\u001b[1;32m   3095\u001b[0m         desc\u001b[39m=\u001b[39mdesc \u001b[39mor\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mMap\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   3096\u001b[0m     ) \u001b[39mas\u001b[39;00m pbar:\n\u001b[0;32m-> 3097\u001b[0m         \u001b[39mfor\u001b[39;00m rank, done, content \u001b[39min\u001b[39;00m Dataset\u001b[39m.\u001b[39m_map_single(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdataset_kwargs):\n\u001b[1;32m   3098\u001b[0m             \u001b[39mif\u001b[39;00m done:\n\u001b[1;32m   3099\u001b[0m                 shards_done \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n","File \u001b[0;32m~/miniconda3/envs/zoomcamp/lib/python3.11/site-packages/datasets/arrow_dataset.py:3450\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[0;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[0m\n\u001b[1;32m   3448\u001b[0m _time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m   3449\u001b[0m \u001b[39mfor\u001b[39;00m i, example \u001b[39min\u001b[39;00m shard_iterable:\n\u001b[0;32m-> 3450\u001b[0m     example \u001b[39m=\u001b[39m apply_function_on_filtered_inputs(example, i, offset\u001b[39m=\u001b[39;49moffset)\n\u001b[1;32m   3451\u001b[0m     \u001b[39mif\u001b[39;00m update_data:\n\u001b[1;32m   3452\u001b[0m         \u001b[39mif\u001b[39;00m i \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n","File \u001b[0;32m~/miniconda3/envs/zoomcamp/lib/python3.11/site-packages/datasets/arrow_dataset.py:3353\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.apply_function_on_filtered_inputs\u001b[0;34m(pa_inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[1;32m   3351\u001b[0m \u001b[39mif\u001b[39;00m with_rank:\n\u001b[1;32m   3352\u001b[0m     additional_args \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (rank,)\n\u001b[0;32m-> 3353\u001b[0m processed_inputs \u001b[39m=\u001b[39m function(\u001b[39m*\u001b[39;49mfn_args, \u001b[39m*\u001b[39;49madditional_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfn_kwargs)\n\u001b[1;32m   3354\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(processed_inputs, LazyDict):\n\u001b[1;32m   3355\u001b[0m     processed_inputs \u001b[39m=\u001b[39m {\n\u001b[1;32m   3356\u001b[0m         k: v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m processed_inputs\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m k \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m processed_inputs\u001b[39m.\u001b[39mkeys_to_format\n\u001b[1;32m   3357\u001b[0m     }\n","Cell \u001b[0;32mIn[46], line 5\u001b[0m, in \u001b[0;36mpreprocess\u001b[0;34m(example)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpreprocess\u001b[39m(example):\n\u001b[0;32m----> 5\u001b[0m     first_sentence \u001b[39m=\u001b[39m [ \u001b[39m\"\u001b[39;49m\u001b[39m[CLS] \u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39m+\u001b[39;49m example[\u001b[39m'\u001b[39;49m\u001b[39mcontext\u001b[39;49m\u001b[39m'\u001b[39;49m] ] \u001b[39m*\u001b[39m \u001b[39m5\u001b[39m\n\u001b[1;32m      6\u001b[0m     second_sentences \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39m #### \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m example[\u001b[39m'\u001b[39m\u001b[39mprompt\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m [SEP] \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m example[option] \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m [SEP]\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mfor\u001b[39;00m option \u001b[39min\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mABCDE\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      7\u001b[0m     tokenized_example \u001b[39m=\u001b[39m tokenizer(first_sentence, second_sentences, truncation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39monly_first\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[1;32m      8\u001b[0m                                   max_length\u001b[39m=\u001b[39mMAX_INPUT, add_special_tokens\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n","\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"NoneType\") to str"]}],"source":["tokenized_dataset_valid = dataset_valid.map(preprocess, remove_columns=['prompt', 'context', 'A', 'B', 'C', 'D', 'E', 'answer'])\n","tokenized_dataset = dataset.map(preprocess, remove_columns=['prompt', 'context', 'A', 'B', 'C', 'D', 'E', 'answer'])\n","tokenized_dataset"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":["from transformers import AutoModel\n","model = AutoModel.from_pretrained(\"microsoft/deberta-v3-large\")"]},{"cell_type":"code","execution_count":30,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-09-18T15:35:17.236416Z","iopub.status.busy":"2023-09-18T15:35:17.235628Z","iopub.status.idle":"2023-09-18T15:35:17.258641Z","shell.execute_reply":"2023-09-18T15:35:17.257700Z","shell.execute_reply.started":"2023-09-18T15:35:17.236352Z"},"trusted":true},"outputs":[],"source":["def map_at_3(predictions, labels):\n","    map_sum = 0\n","    pred = np.argsort(-1*np.array(predictions),axis=1)[:,:3]\n","    for x,y in zip(pred,labels):\n","        z = [1/i if y==j else 0 for i,j in zip([1,2,3],x)]\n","        map_sum += np.sum(z)\n","    return map_sum / len(predictions)\n","\n","def compute_metrics(p):\n","    predictions = p.predictions.tolist()\n","    labels = p.label_ids.tolist()\n","    return {\"map@3\": map_at_3(predictions, labels)}"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[],"source":["training_args = TrainingArguments(\n","    warmup_ratio=0.1, \n","    learning_rate=6e-6,\n","    per_device_train_batch_size=1,\n","    per_device_eval_batch_size=2,\n","    num_train_epochs=1,\n","    report_to='none',\n","    output_dir = f'./checkpoints_{VER}',\n","    overwrite_output_dir=True,\n","    fp16=False,\n","#     gradient_accumulation_steps=8,\n","    logging_steps=250,\n","    evaluation_strategy='steps',\n","    eval_steps=250,\n","    save_strategy=\"steps\",\n","    save_steps=250,\n","    load_best_model_at_end=True,\n","    metric_for_best_model='map@3',\n","    lr_scheduler_type='cosine',\n","    weight_decay=0.01,\n","    save_total_limit=2,\n",")"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 0/31007 [00:00<?, ?it/s]You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"]},{"ename":"TypeError","evalue":"DebertaV2Model.forward() got an unexpected keyword argument 'labels'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[32], line 12\u001b[0m\n\u001b[1;32m      1\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(\n\u001b[1;32m      2\u001b[0m     model\u001b[39m=\u001b[39mmodel,\n\u001b[1;32m      3\u001b[0m     args\u001b[39m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m     callbacks\u001b[39m=\u001b[39m[EarlyStoppingCallback(early_stopping_patience\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)],\n\u001b[1;32m     10\u001b[0m )\n\u001b[0;32m---> 12\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n\u001b[1;32m     13\u001b[0m trainer\u001b[39m.\u001b[39msave_model(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmodel_v\u001b[39m\u001b[39m{\u001b[39;00mVER\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n","File \u001b[0;32m~/miniconda3/envs/zoomcamp/lib/python3.11/site-packages/transformers/trainer.py:1553\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m         hf_hub_utils\u001b[39m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1554\u001b[0m         args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m   1555\u001b[0m         resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[1;32m   1556\u001b[0m         trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[1;32m   1557\u001b[0m         ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[1;32m   1558\u001b[0m     )\n","File \u001b[0;32m~/miniconda3/envs/zoomcamp/lib/python3.11/site-packages/transformers/trainer.py:1835\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1832\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_handler\u001b[39m.\u001b[39mon_step_begin(args, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol)\n\u001b[1;32m   1834\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccelerator\u001b[39m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 1835\u001b[0m     tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_step(model, inputs)\n\u001b[1;32m   1837\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   1838\u001b[0m     args\u001b[39m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1839\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1840\u001b[0m     \u001b[39mand\u001b[39;00m (torch\u001b[39m.\u001b[39misnan(tr_loss_step) \u001b[39mor\u001b[39;00m torch\u001b[39m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1841\u001b[0m ):\n\u001b[1;32m   1842\u001b[0m     \u001b[39m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1843\u001b[0m     tr_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tr_loss \u001b[39m/\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_globalstep_last_logged)\n","File \u001b[0;32m~/miniconda3/envs/zoomcamp/lib/python3.11/site-packages/transformers/trainer.py:2679\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2676\u001b[0m     \u001b[39mreturn\u001b[39;00m loss_mb\u001b[39m.\u001b[39mreduce_mean()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m   2678\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 2679\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_loss(model, inputs)\n\u001b[1;32m   2681\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mn_gpu \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   2682\u001b[0m     loss \u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mmean()  \u001b[39m# mean() to average on multi-gpu parallel training\u001b[39;00m\n","File \u001b[0;32m~/miniconda3/envs/zoomcamp/lib/python3.11/site-packages/transformers/trainer.py:2704\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2702\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2703\u001b[0m     labels \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 2704\u001b[0m outputs \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minputs)\n\u001b[1;32m   2705\u001b[0m \u001b[39m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   2706\u001b[0m \u001b[39m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   2707\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mpast_index \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n","File \u001b[0;32m~/miniconda3/envs/zoomcamp/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","\u001b[0;31mTypeError\u001b[0m: DebertaV2Model.forward() got an unexpected keyword argument 'labels'"]}],"source":["trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    tokenizer=tokenizer,\n","    data_collator=DataCollatorForMultipleChoice(tokenizer=tokenizer),\n","    train_dataset=tokenized_dataset,\n","    eval_dataset=tokenized_dataset_valid,\n","    compute_metrics = compute_metrics,\n","    callbacks=[EarlyStoppingCallback(early_stopping_patience=5)],\n",")\n","\n","trainer.train()\n","trainer.save_model(f'model_v{VER}')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-09-18T15:35:19.517440Z","iopub.status.busy":"2023-09-18T15:35:19.517046Z","iopub.status.idle":"2023-09-18T15:35:27.422940Z","shell.execute_reply":"2023-09-18T15:35:27.421920Z","shell.execute_reply.started":"2023-09-18T15:35:19.517407Z"},"trusted":true},"outputs":[],"source":["df_train = pd.read_csv('data/all_12_with_context2.csv')\n","df_train.fillna(\"-\", inplace=True)\n","df_train = df_train.drop(['context','source'],axis=1).reset_index()\n","df_train = df_train.rename({'index':'id'}, axis=1)\n","train_df = pd.concat([train_df, df_train])\n","train_df.reset_index(drop=True, inplace=True)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-09-18T15:35:31.197941Z","iopub.status.busy":"2023-09-18T15:35:31.197578Z","iopub.status.idle":"2023-09-18T15:35:31.271023Z","shell.execute_reply":"2023-09-18T15:35:31.270042Z","shell.execute_reply.started":"2023-09-18T15:35:31.197910Z"},"trusted":true},"outputs":[],"source":["train_ds = Dataset.from_pandas(train_df)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-09-18T17:00:53.468929Z","iopub.status.busy":"2023-09-18T17:00:53.468546Z","iopub.status.idle":"2023-09-18T17:00:53.487234Z","shell.execute_reply":"2023-09-18T17:00:53.486075Z","shell.execute_reply.started":"2023-09-18T17:00:53.468898Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>prompt</th>\n","      <th>context</th>\n","      <th>A</th>\n","      <th>B</th>\n","      <th>C</th>\n","      <th>D</th>\n","      <th>E</th>\n","      <th>answer</th>\n","      <th>source</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>In relation to Eunice Fay McKenzie's career, w...</td>\n","      <td>Eunice Fay McKenzie (February 19, 1918 – April...</td>\n","      <td>McKenzie showcased her singing talents in nume...</td>\n","      <td>McKenzie is primarily remembered for her starr...</td>\n","      <td>McKenzie gained recognition for her role as a ...</td>\n","      <td>McKenzie's collaborations with director Blake ...</td>\n","      <td>McKenzie's successful career in sound films co...</td>\n","      <td>B</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>How does Modified Newtonian Dynamics (MOND) im...</td>\n","      <td>The presence of a clustered thick disk-like co...</td>\n","      <td>MOND is a theory that increases the discrepanc...</td>\n","      <td>MOND explains the missing baryonic mass in gal...</td>\n","      <td>MOND is a theory that reduces the observed mis...</td>\n","      <td>MOND is a theory that eliminates the observed ...</td>\n","      <td>MOND's impact on the observed missing baryonic...</td>\n","      <td>E</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Which of the following statements accurately d...</td>\n","      <td>Woody Hartman is a retired American soccer goa...</td>\n","      <td>Ray Montgomerie is a former footballer who pla...</td>\n","      <td>Ray Montgomerie is a former footballer who pla...</td>\n","      <td>Ray Montgomerie is a former footballer who pla...</td>\n","      <td>Ray Montgomerie is a former footballer who pla...</td>\n","      <td>Ray Montgomerie is a former footballer who pla...</td>\n","      <td>B</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                              prompt  \\\n","0  In relation to Eunice Fay McKenzie's career, w...   \n","1  How does Modified Newtonian Dynamics (MOND) im...   \n","2  Which of the following statements accurately d...   \n","\n","                                             context  \\\n","0  Eunice Fay McKenzie (February 19, 1918 – April...   \n","1  The presence of a clustered thick disk-like co...   \n","2  Woody Hartman is a retired American soccer goa...   \n","\n","                                                   A  \\\n","0  McKenzie showcased her singing talents in nume...   \n","1  MOND is a theory that increases the discrepanc...   \n","2  Ray Montgomerie is a former footballer who pla...   \n","\n","                                                   B  \\\n","0  McKenzie is primarily remembered for her starr...   \n","1  MOND explains the missing baryonic mass in gal...   \n","2  Ray Montgomerie is a former footballer who pla...   \n","\n","                                                   C  \\\n","0  McKenzie gained recognition for her role as a ...   \n","1  MOND is a theory that reduces the observed mis...   \n","2  Ray Montgomerie is a former footballer who pla...   \n","\n","                                                   D  \\\n","0  McKenzie's collaborations with director Blake ...   \n","1  MOND is a theory that eliminates the observed ...   \n","2  Ray Montgomerie is a former footballer who pla...   \n","\n","                                                   E answer  source  \n","0  McKenzie's successful career in sound films co...      B       1  \n","1  MOND's impact on the observed missing baryonic...      E       1  \n","2  Ray Montgomerie is a former footballer who pla...      B       1  "]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["df_train.head(3)"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"ename":"ValueError","evalue":"text input must of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples).","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m features \u001b[39m=\u001b[39m tokenizer(\n\u001b[1;32m      2\u001b[0m     df_train[\u001b[39m\"\u001b[39;49m\u001b[39mprompt\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m      3\u001b[0m     df_train[\u001b[39m\"\u001b[39;49m\u001b[39mcontext\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m      4\u001b[0m     max_length \u001b[39m=\u001b[39;49m \u001b[39m384\u001b[39;49m,\n\u001b[1;32m      5\u001b[0m     truncation\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39monly_second\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      6\u001b[0m     padding \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mmax_length\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      8\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(tokenizer\u001b[39m.\u001b[39mbatch_decode(features[\u001b[39m\"\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m\"\u001b[39m])))\n","File \u001b[0;32m~/miniconda3/envs/zoomcamp/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2602\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[0;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2600\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_in_target_context_manager:\n\u001b[1;32m   2601\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_switch_to_input_mode()\n\u001b[0;32m-> 2602\u001b[0m     encodings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_one(text\u001b[39m=\u001b[39;49mtext, text_pair\u001b[39m=\u001b[39;49mtext_pair, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mall_kwargs)\n\u001b[1;32m   2603\u001b[0m \u001b[39mif\u001b[39;00m text_target \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2604\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_switch_to_target_mode()\n","File \u001b[0;32m~/miniconda3/envs/zoomcamp/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2660\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._call_one\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2657\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   2659\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _is_valid_text_input(text):\n\u001b[0;32m-> 2660\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   2661\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtext input must of type `str` (single example), `List[str]` (batch or single pretokenized example) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2662\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mor `List[List[str]]` (batch of pretokenized examples).\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2663\u001b[0m     )\n\u001b[1;32m   2665\u001b[0m \u001b[39mif\u001b[39;00m text_pair \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m _is_valid_text_input(text_pair):\n\u001b[1;32m   2666\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   2667\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtext input must of type `str` (single example), `List[str]` (batch or single pretokenized example) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2668\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mor `List[List[str]]` (batch of pretokenized examples).\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2669\u001b[0m     )\n","\u001b[0;31mValueError\u001b[0m: text input must of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples)."]}],"source":["features = tokenizer(\n","    df_train[\"prompt\"],\n","    df_train[\"context\"],\n","    max_length = 384,\n","    truncation=\"only_second\",\n","    padding = \"max_length\",\n",")\n","print(\"\".join(tokenizer.batch_decode(features[\"input_ids\"])))"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-09-18T15:37:23.050144Z","iopub.status.busy":"2023-09-18T15:37:23.049792Z","iopub.status.idle":"2023-09-18T15:37:23.055247Z","shell.execute_reply":"2023-09-18T15:37:23.054352Z","shell.execute_reply.started":"2023-09-18T15:37:23.050118Z"},"trusted":true},"outputs":[],"source":["#We'll create a dictionary to convert option names (A, B, C, D, E) into indices and back again\n","options = 'ABCDE'\n","indices = list(range(5))\n","\n","option_to_index = {option: index for option, index in zip(options, indices)}\n","index_to_option = {index: option for option, index in zip(options, indices)}"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-09-18T15:37:29.812645Z","iopub.status.busy":"2023-09-18T15:37:29.812269Z","iopub.status.idle":"2023-09-18T15:38:35.991185Z","shell.execute_reply":"2023-09-18T15:38:35.990189Z","shell.execute_reply.started":"2023-09-18T15:37:29.812615Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4ab2fcdfa9fd44aaaabf1b9521408c06","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/60547 [00:00<?, ?ex/s]"]},"metadata":{},"output_type":"display_data"}],"source":["def preprocess(example):\n","    # The AutoModelForMultipleChoice class expects a set of question/answer pairs\n","    # so we'll copy our question 5 times before tokenizing\n","    first_sentence = [example['prompt']] * 5\n","    second_sentence = []\n","    for option in options:\n","        second_sentence.append(example[option])\n","    # Our tokenizer will turn our text into token IDs BERT can understand\n","    tokenized_example = tokenizer(first_sentence, second_sentence, truncation=True, max_length=384)\n","    tokenized_example['label'] = option_to_index[example['answer']]\n","    return tokenized_example\n","\n","tokenized_train_ds = train_ds.map(preprocess, batched=False, remove_columns=['prompt', 'A', 'B', 'C', 'D', 'E', 'answer'])"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-09-18T15:38:40.875056Z","iopub.status.busy":"2023-09-18T15:38:40.874686Z","iopub.status.idle":"2023-09-18T15:38:40.881980Z","shell.execute_reply":"2023-09-18T15:38:40.880957Z","shell.execute_reply.started":"2023-09-18T15:38:40.875026Z"},"trusted":true},"outputs":[{"data":{"text/plain":["Dataset({\n","    features: ['id', 'input_ids', 'token_type_ids', 'attention_mask', 'label'],\n","    num_rows: 60547\n","})"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["tokenized_train_ds"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-09-18T15:38:54.837247Z","iopub.status.busy":"2023-09-18T15:38:54.836554Z","iopub.status.idle":"2023-09-18T15:38:57.772172Z","shell.execute_reply":"2023-09-18T15:38:57.771204Z","shell.execute_reply.started":"2023-09-18T15:38:54.837208Z"},"trusted":true},"outputs":[],"source":["# Following datacollator (adapted from https://huggingface.co/docs/transformers/tasks/multiple_choice)\n","# will dynamically pad our questions at batch-time so we don't have to make every question the length\n","# of our longest question.\n","from dataclasses import dataclass\n","from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n","from typing import Optional, Union\n","import torch\n","\n","@dataclass\n","class DataCollatorForMultipleChoice:\n","    tokenizer: PreTrainedTokenizerBase\n","    padding: Union[bool, str, PaddingStrategy] = True\n","    max_length: Optional[int] = None\n","    pad_to_multiple_of: Optional[int] = None\n","    \n","    def __call__(self, features):\n","        label_name = \"label\" if 'label' in features[0].keys() else 'labels'\n","        labels = [feature.pop(label_name) for feature in features]\n","        batch_size = len(features)\n","        num_choices = len(features[0]['input_ids'])\n","        flattened_features = [\n","            [{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features\n","        ]\n","        flattened_features = sum(flattened_features, [])\n","        \n","        batch = self.tokenizer.pad(\n","            flattened_features,\n","            padding=self.padding,\n","            max_length=self.max_length,\n","            pad_to_multiple_of=self.pad_to_multiple_of,\n","            return_tensors='pt',\n","        )\n","        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n","        batch['labels'] = torch.tensor(labels, dtype=torch.int64)\n","        return batch"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-09-18T15:38:59.142311Z","iopub.status.busy":"2023-09-18T15:38:59.141659Z","iopub.status.idle":"2023-09-18T15:39:15.845174Z","shell.execute_reply":"2023-09-18T15:39:15.844256Z","shell.execute_reply.started":"2023-09-18T15:38:59.142279Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n","  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n","caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n","  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n","/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n","caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n","  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","Some weights of the model checkpoint at /kaggle/input/huggingface-bert/bert-base-cased were not used when initializing BertForMultipleChoice: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMultipleChoice from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMultipleChoice from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForMultipleChoice were not initialized from the model checkpoint at /kaggle/input/huggingface-bert/bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["# Now we'll instatiate the model that we'll finetune on our public dataset, then use to\n","# make prediction on the private dataset.\n","from transformers import AutoModelForMultipleChoice, TrainingArguments, Trainer\n","model = AutoModelForMultipleChoice.from_pretrained(model_dir)"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-09-18T15:46:23.704331Z","iopub.status.busy":"2023-09-18T15:46:23.703471Z","iopub.status.idle":"2023-09-18T15:46:23.711735Z","shell.execute_reply":"2023-09-18T15:46:23.710590Z","shell.execute_reply.started":"2023-09-18T15:46:23.704294Z"},"trusted":true},"outputs":[],"source":["# The arguments here are selected to run quickly; feel free to play with them.\n","model_dir = 'finetuned_bert'\n","training_args = TrainingArguments(\n","    output_dir=model_dir,\n","    evaluation_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    load_best_model_at_end=True,\n","    learning_rate=5e-5,\n","    per_device_train_batch_size=4,\n","    per_device_eval_batch_size=4,\n","    num_train_epochs=1,\n","    weight_decay=0.01,\n","    report_to='none'\n",")"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-09-18T15:46:26.768708Z","iopub.status.busy":"2023-09-18T15:46:26.768018Z","iopub.status.idle":"2023-09-18T15:46:26.788677Z","shell.execute_reply":"2023-09-18T15:46:26.787808Z","shell.execute_reply.started":"2023-09-18T15:46:26.768677Z"},"trusted":true},"outputs":[],"source":["# Generally it's a bad idea to validate on your training set, but because our training set\n","# for this problem is so small we're going to train on all our data.\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized_train_ds,\n","    eval_dataset=tokenized_train_ds,\n","    tokenizer=tokenizer,\n","    data_collator=DataCollatorForMultipleChoice(tokenizer=tokenizer),\n",")"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2023-09-18T15:46:29.340055Z","iopub.status.busy":"2023-09-18T15:46:29.339680Z","iopub.status.idle":"2023-09-18T16:27:34.007274Z","shell.execute_reply":"2023-09-18T16:27:34.006302Z","shell.execute_reply.started":"2023-09-18T15:46:29.340026Z"},"trusted":true},"outputs":[{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='15137' max='15137' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [15137/15137 41:04, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.616100</td>\n","      <td>1.609438</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["TrainOutput(global_step=15137, training_loss=1.6154593204171432, metrics={'train_runtime': 2464.1302, 'train_samples_per_second': 24.571, 'train_steps_per_second': 6.143, 'total_flos': 8509212628810920.0, 'train_loss': 1.6154593204171432, 'epoch': 1.0})"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["# Training should take about a minute\n","trainer.train()"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2023-09-18T16:29:25.088301Z","iopub.status.busy":"2023-09-18T16:29:25.087254Z","iopub.status.idle":"2023-09-18T16:38:35.032188Z","shell.execute_reply":"2023-09-18T16:38:35.031270Z","shell.execute_reply.started":"2023-09-18T16:29:25.088265Z"},"trusted":true},"outputs":[{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["# Now we can actually make predictions on our questions\n","predictions = trainer.predict(tokenized_train_ds)"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2023-09-18T16:41:50.533329Z","iopub.status.busy":"2023-09-18T16:41:50.532247Z","iopub.status.idle":"2023-09-18T16:41:50.540134Z","shell.execute_reply":"2023-09-18T16:41:50.538926Z","shell.execute_reply.started":"2023-09-18T16:41:50.533272Z"},"trusted":true},"outputs":[],"source":["# The following function gets the indices of the highest scoring answers for each row\n","# and converts them back to our answer format (A, B, C, D, E)\n","import numpy as np\n","def predictions_to_map_output(predictions):\n","    sorted_answer_indices = np.argsort(-predictions)\n","    top_answer_indices = sorted_answer_indices[:,:3] # Get the first three answers in each row\n","    top_answers = np.vectorize(index_to_option.get)(top_answer_indices)\n","    return np.apply_along_axis(lambda row: ' '.join(row), 1, top_answers)\n","    "]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2023-09-18T16:41:53.970343Z","iopub.status.busy":"2023-09-18T16:41:53.969966Z","iopub.status.idle":"2023-09-18T16:41:54.406483Z","shell.execute_reply":"2023-09-18T16:41:54.405430Z","shell.execute_reply.started":"2023-09-18T16:41:53.970310Z"},"trusted":true},"outputs":[{"data":{"text/plain":["array(['B D E', 'D A C', 'A B C', ..., 'C A B', 'B D E', 'B D E'],\n","      dtype='<U5')"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["# Let's double check our output looks correct:\n","predictions_to_map_output(predictions.predictions)"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2023-09-18T16:42:00.575761Z","iopub.status.busy":"2023-09-18T16:42:00.574512Z","iopub.status.idle":"2023-09-18T16:42:00.607471Z","shell.execute_reply":"2023-09-18T16:42:00.606384Z","shell.execute_reply.started":"2023-09-18T16:42:00.575713Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>prompt</th>\n","      <th>A</th>\n","      <th>B</th>\n","      <th>C</th>\n","      <th>D</th>\n","      <th>E</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>Which of the following statements accurately d...</td>\n","      <td>MOND is a theory that reduces the observed mis...</td>\n","      <td>MOND is a theory that increases the discrepanc...</td>\n","      <td>MOND is a theory that explains the missing bar...</td>\n","      <td>MOND is a theory that reduces the discrepancy ...</td>\n","      <td>MOND is a theory that eliminates the observed ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>Which of the following is an accurate definiti...</td>\n","      <td>Dynamic scaling refers to the evolution of sel...</td>\n","      <td>Dynamic scaling refers to the non-evolution of...</td>\n","      <td>Dynamic scaling refers to the evolution of sel...</td>\n","      <td>Dynamic scaling refers to the non-evolution of...</td>\n","      <td>Dynamic scaling refers to the evolution of sel...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>Which of the following statements accurately d...</td>\n","      <td>The triskeles symbol was reconstructed as a fe...</td>\n","      <td>The triskeles symbol is a representation of th...</td>\n","      <td>The triskeles symbol is a representation of a ...</td>\n","      <td>The triskeles symbol represents three interloc...</td>\n","      <td>The triskeles symbol is a representation of th...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>What is the significance of regularization in ...</td>\n","      <td>Regularizing the mass-energy of an electron wi...</td>\n","      <td>Regularizing the mass-energy of an electron wi...</td>\n","      <td>Regularizing the mass-energy of an electron wi...</td>\n","      <td>Regularizing the mass-energy of an electron wi...</td>\n","      <td>Regularizing the mass-energy of an electron wi...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>Which of the following statements accurately d...</td>\n","      <td>The angular spacing of features in the diffrac...</td>\n","      <td>The angular spacing of features in the diffrac...</td>\n","      <td>The angular spacing of features in the diffrac...</td>\n","      <td>The angular spacing of features in the diffrac...</td>\n","      <td>The angular spacing of features in the diffrac...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id                                             prompt  \\\n","0   0  Which of the following statements accurately d...   \n","1   1  Which of the following is an accurate definiti...   \n","2   2  Which of the following statements accurately d...   \n","3   3  What is the significance of regularization in ...   \n","4   4  Which of the following statements accurately d...   \n","\n","                                                   A  \\\n","0  MOND is a theory that reduces the observed mis...   \n","1  Dynamic scaling refers to the evolution of sel...   \n","2  The triskeles symbol was reconstructed as a fe...   \n","3  Regularizing the mass-energy of an electron wi...   \n","4  The angular spacing of features in the diffrac...   \n","\n","                                                   B  \\\n","0  MOND is a theory that increases the discrepanc...   \n","1  Dynamic scaling refers to the non-evolution of...   \n","2  The triskeles symbol is a representation of th...   \n","3  Regularizing the mass-energy of an electron wi...   \n","4  The angular spacing of features in the diffrac...   \n","\n","                                                   C  \\\n","0  MOND is a theory that explains the missing bar...   \n","1  Dynamic scaling refers to the evolution of sel...   \n","2  The triskeles symbol is a representation of a ...   \n","3  Regularizing the mass-energy of an electron wi...   \n","4  The angular spacing of features in the diffrac...   \n","\n","                                                   D  \\\n","0  MOND is a theory that reduces the discrepancy ...   \n","1  Dynamic scaling refers to the non-evolution of...   \n","2  The triskeles symbol represents three interloc...   \n","3  Regularizing the mass-energy of an electron wi...   \n","4  The angular spacing of features in the diffrac...   \n","\n","                                                   E  \n","0  MOND is a theory that eliminates the observed ...  \n","1  Dynamic scaling refers to the evolution of sel...  \n","2  The triskeles symbol is a representation of th...  \n","3  Regularizing the mass-energy of an electron wi...  \n","4  The angular spacing of features in the diffrac...  "]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["# Now we can load up our test set to use our model on!\n","# The public test.csv isn't the real dataset (it's actually just a copy of train.csv without the answer column)\n","# but it has the same format as the real test set, so using it is a good way to ensure our code will work when we submit.\n","test_df = pd.read_csv('/kaggle/input/kaggle-llm-science-exam/test.csv')\n","test_df.head()"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2023-09-18T16:42:03.591900Z","iopub.status.busy":"2023-09-18T16:42:03.591221Z","iopub.status.idle":"2023-09-18T16:42:03.922802Z","shell.execute_reply":"2023-09-18T16:42:03.921759Z","shell.execute_reply.started":"2023-09-18T16:42:03.591866Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0ffa1986457446ddb19912bd77ee3d1b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/200 [00:00<?, ?ex/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# There are more verbose/elegant ways of doing this, but if we give our test set a random `answer` column\n","# we can make predictions directly with our trainer.\n","test_df['answer'] = 'A'\n","\n","# Other than that we'll preprocess it in the same way we preprocessed test.csv\n","test_ds = Dataset.from_pandas(test_df)\n","tokenized_test_ds = test_ds.map(preprocess, batched=False, remove_columns=['prompt', 'A', 'B', 'C', 'D', 'E', 'answer'])\n"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2023-09-18T16:42:08.005573Z","iopub.status.busy":"2023-09-18T16:42:08.004804Z","iopub.status.idle":"2023-09-18T16:42:10.883917Z","shell.execute_reply":"2023-09-18T16:42:10.882848Z","shell.execute_reply.started":"2023-09-18T16:42:08.005534Z"},"trusted":true},"outputs":[{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["# Here we'll generate our \"real\" predictions on the test set\n","test_predictions = trainer.predict(tokenized_test_ds)"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2023-09-18T16:42:14.071183Z","iopub.status.busy":"2023-09-18T16:42:14.070773Z","iopub.status.idle":"2023-09-18T16:42:14.087202Z","shell.execute_reply":"2023-09-18T16:42:14.085940Z","shell.execute_reply.started":"2023-09-18T16:42:14.071148Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_28/1317637749.py:3: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  submission_df['prediction'] = predictions_to_map_output(test_predictions.predictions)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>prediction</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>B D E</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>D A C</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>A B C</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>E C B</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>A C B</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id prediction\n","0   0      B D E\n","1   1      D A C\n","2   2      A B C\n","3   3      E C B\n","4   4      A C B"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["# Now we can create our submission using the id column from test.csv\n","submission_df = test_df[['id']]\n","submission_df['prediction'] = predictions_to_map_output(test_predictions.predictions)\n","\n","submission_df.head()"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2023-09-18T16:43:43.282843Z","iopub.status.busy":"2023-09-18T16:43:43.282440Z","iopub.status.idle":"2023-09-18T16:43:43.292072Z","shell.execute_reply":"2023-09-18T16:43:43.290987Z","shell.execute_reply.started":"2023-09-18T16:43:43.282811Z"},"trusted":true},"outputs":[],"source":["# Once we write our submission file we're good to submit!\n","submission_df.to_csv('submission_s.csv', index=False)"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2023-09-18T16:42:21.837818Z","iopub.status.busy":"2023-09-18T16:42:21.837449Z","iopub.status.idle":"2023-09-18T16:42:21.849813Z","shell.execute_reply":"2023-09-18T16:42:21.848737Z","shell.execute_reply.started":"2023-09-18T16:42:21.837789Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>prediction</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>B D E</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>D A C</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>A B C</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>E C B</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>A C B</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>195</th>\n","      <td>195</td>\n","      <td>C E A</td>\n","    </tr>\n","    <tr>\n","      <th>196</th>\n","      <td>196</td>\n","      <td>D C B</td>\n","    </tr>\n","    <tr>\n","      <th>197</th>\n","      <td>197</td>\n","      <td>B A E</td>\n","    </tr>\n","    <tr>\n","      <th>198</th>\n","      <td>198</td>\n","      <td>C A B</td>\n","    </tr>\n","    <tr>\n","      <th>199</th>\n","      <td>199</td>\n","      <td>D B C</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>200 rows × 2 columns</p>\n","</div>"],"text/plain":["      id prediction\n","0      0      B D E\n","1      1      D A C\n","2      2      A B C\n","3      3      E C B\n","4      4      A C B\n","..   ...        ...\n","195  195      C E A\n","196  196      D C B\n","197  197      B A E\n","198  198      C A B\n","199  199      D B C\n","\n","[200 rows x 2 columns]"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["submission_df"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":4}
